{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/appletime/anaconda3/envs/ML/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils import Vocab\n",
    "from model import SeqTagger\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import SeqTaggingClsDataset\n",
    "\n",
    "from seqeval.scheme import IOB2\n",
    "from seqeval.metrics import f1_score\n",
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cache/slot/vocab.pkl\", \"rb\") as f:\n",
    "    vocab: Vocab = pickle.load(f)\n",
    "embeddings = torch.load(\"cache/slot/embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-date': 0,\n",
       " 'I-people': 1,\n",
       " 'B-people': 2,\n",
       " 'B-first_name': 3,\n",
       " 'B-time': 4,\n",
       " 'B-date': 5,\n",
       " 'B-last_name': 6,\n",
       " 'O': 7,\n",
       " 'I-time': 8}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx: Dict[str, int] = json.loads(Path(\"cache/slot/tag2idx.json\").read_text())\n",
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 40\n",
    "batch_size = 1\n",
    "eval_file_path = Path(\"data/slot/eval.json\")\n",
    "eval_data = json.loads(eval_file_path.read_text())\n",
    "eval_dataset = SeqTaggingClsDataset(eval_data, vocab, tag2idx, max_len)\n",
    "\n",
    "eval_data_loader = DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=eval_dataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqTagger(\n",
       "  (embed): Embedding(4117, 300)\n",
       "  (rnn): GRU(300, 512, num_layers=4, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=1024, out_features=9, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (linear): Linear(in_features=1024, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 512\n",
    "num_layers = 4\n",
    "dropout = 0.1\n",
    "bidirectional = True\n",
    "device = \"cuda\"\n",
    "\n",
    "# load model\n",
    "model = SeqTagger(\n",
    "    embeddings,\n",
    "    hidden_size,\n",
    "    num_layers,\n",
    "    dropout,\n",
    "    bidirectional,\n",
    "    len(tag2idx)\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(\"ckpt/slot/slot_model.pt\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/appletime/文件/GitHub/ADL21-HW1/model.py:101: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(affine_out)\n"
     ]
    }
   ],
   "source": [
    "result_dict = {\n",
    "    \"id\": list(),\n",
    "    \"tags\": list()\n",
    "}\n",
    "count = 0\n",
    "for batch in eval_data_loader:\n",
    "    ids = batch[\"ids\"].to(device)\n",
    "    pred = model(ids).to(device)\n",
    "    sentence_len = len(eval_data[count].get(\"tokens\"))\n",
    "    pred_res = pred.argmax(dim=1).tolist()[:sentence_len]\n",
    "    pred_res = [eval_dataset.idx2label(res) for res in pred_res]\n",
    "    pred_res_str = \" \".join(pred_res)\n",
    "\n",
    "    result_dict[\"id\"].append(eval_data[count][\"id\"])\n",
    "    result_dict[\"tags\"].append(pred_res)\n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['O', 'O', 'O', 'O', 'O'],\n",
       " ['B-time', 'O'],\n",
       " ['O', 'O', 'B-people'],\n",
       " ['O', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['O', 'O', 'B-date', 'I-date', 'I-date']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['O', 'O', 'O', 'O', 'O'],\n",
       " ['B-time', 'O'],\n",
       " ['O', 'O', 'B-people'],\n",
       " ['O', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['O', 'O', 'B-date', 'I-date', 'I-date']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = result_dict.get(\"tags\")\n",
    "\n",
    "y_true = [\n",
    "    item.get(\"tags\")\n",
    "    for item in eval_data\n",
    "]\n",
    "\n",
    "display(y_pred[:5])\n",
    "print(\"-\" * 59)\n",
    "display(y_true[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval_test_report = classification_report(y_true, y_pred, mode='strict', scheme=IOB2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['              precision    recall  f1-score   support',\n",
      " '',\n",
      " '        date       0.76      0.67      0.71       206',\n",
      " '  first_name       0.84      0.87      0.86       102',\n",
      " '   last_name       0.68      0.74      0.71        78',\n",
      " '      people       0.61      0.60      0.60       238',\n",
      " '        time       0.72      0.84      0.78       218',\n",
      " '',\n",
      " '   micro avg       0.71      0.73      0.72       842',\n",
      " '   macro avg       0.72      0.75      0.73       842',\n",
      " 'weighted avg       0.71      0.73      0.72       842',\n",
      " '']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(seqeval_test_report.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0] == y_true[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint Accuracy = 728 / 1000\n"
     ]
    }
   ],
   "source": [
    "joint_correct_count = 0\n",
    "for pred_list, true_list in zip(y_pred, y_true):\n",
    "    if pred_list == true_list:\n",
    "        joint_correct_count += 1\n",
    "\n",
    "print(f\"Joint Accuracy = {joint_correct_count} / {len(y_true)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Accuracy = 7511 / 7891\n"
     ]
    }
   ],
   "source": [
    "token_correct_count = 0\n",
    "all_token_count = 0\n",
    "for pred_list, true_list in zip(y_pred, y_true):\n",
    "    all_token_count += len(pred_list)\n",
    "    for pred_value, true_value in zip(pred_list, true_list):\n",
    "        if pred_value == true_value:\n",
    "            token_correct_count += 1\n",
    "            \n",
    "print(f\"Token Accuracy = {token_correct_count} / {all_token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.18438727664427"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "751100 / 7891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9518438727664428"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
